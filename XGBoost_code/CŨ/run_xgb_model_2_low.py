import pandas as pd
import numpy as np
import xgboost as xgb
# (TH√äM MAE)
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error 
import time

#  1. C√†i ƒë·∫∑t C·∫•u h√¨nh (M√¥ h√¨nh 2: Nh√≥m ·ªîn ƒë·ªãnh) 

HIGH_VOLUME_FAMILIES = [
    'GROCERY I', 'PRODUCE', 'BEVERAGES', 'DAIRY',
    'BREAD/BAKERY', 'DELI', 'EGGS'
]

N_FOLDS = 5

features_low = [
    'store_nbr', 'family', 'city', 'state', 'type', 'cluster', 
    'dcoilwtico', 'is_holiday', 'day_of_week', 'week_of_year', 'month', 'year', 
    'is_weekend'
]
target = 'sales'

categorical_features_low = [
    'store_nbr', 'family', 'city', 'state', 'type', 
    'cluster', 'is_holiday', 'day_of_week', 'month', 'year', 'is_weekend'
]

all_results_dfs = []

print(f"B·∫Øt ƒë·∫ßu K·∫ø ho·∫°ch 'Chia ƒë·ªÉ tr·ªã' (M√¥ h√¨nh 2 - S·ª≠a l·ªói)...")
print(f"Train cho nh√≥m '·ªîn ƒë·ªãnh' (d√πng m·ª•c ti√™u Tweedie).")
start_time = time.time()

#  2. Ch·∫°y V√≤ng l·∫∑p 5-Fold Cross-Validation 

for fold in range(1, N_FOLDS + 1):
    print(f" ƒêang ch·∫°y Fold {fold}/{N_FOLDS} ")
    
    train_file = f'folds/train_fold_{fold}.csv'
    test_file = f'folds/test_fold_{fold}.csv'
    
    df_train = pd.read_csv(train_file)
    df_test = pd.read_csv(test_file)
    
    # L·ªçc data: Lo·∫°i tr·ª´ 7 nh√≥m cao
    df_train = df_train[~df_train['family'].isin(HIGH_VOLUME_FAMILIES)].copy()
    df_test = df_test[~df_test['family'].isin(HIGH_VOLUME_FAMILIES)].copy()
    
    df_train[features_low] = df_train[features_low].fillna(0)
    df_test[features_low] = df_test[features_low].fillna(0)
    
    print(f"Fold {fold}: ƒêang x·ª≠ l√Ω categorical features...")
    for col in categorical_features_low:
        all_categories = pd.concat([df_train[col], df_test[col]]).unique()
        df_train[col] = pd.Categorical(df_train[col], categories=all_categories)
        df_test[col] = pd.Categorical(df_test[col], categories=all_categories)

    X_train = df_train[features_low]
    y_train = df_train[target]
    
    X_test = df_test[features_low]
    y_test = df_test[target]
    
    # 6. Kh·ªüi t·∫°o v√† Hu·∫•n luy·ªán (THAY ƒê·ªîI QUAN TR·ªåNG)
    # S·ª≠ d·ª•ng 'reg:tweedie' thay v√¨ 'reg:squarederror'
    xgb_model_low = xgb.XGBRegressor(
        objective='reg:tweedie',    # < THAY ƒê·ªîI
        tweedie_variance_power=1.5, # (tham s·ªë cho Tweedie, 1.5 l√† ƒëi·ªÉm kh·ªüi ƒë·∫ßu t·ªët)
        eval_metric='rmse',         # (V·∫´n theo d√µi RMSE, nh∆∞ng m·ª•c ti√™u l√† Tweedie)
        n_estimators=1000,
        learning_rate=0.05,
        max_depth=6,
        n_jobs=-1,
        random_state=42,
        early_stopping_rounds=100,
        enable_categorical=True
    )
    
    print(f"Fold {fold}: B·∫Øt ƒë·∫ßu training XGBoost (Tweedie)...")
    xgb_model_low.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=False
    )
    print(f"Fold {fold}: Training ho√†n t·∫•t. B·∫Øt ƒë·∫ßu d·ª± ƒëo√°n...")
    
    preds = xgb_model_low.predict(X_test)
    
    df_test_results = df_test[['family', 'sales']].copy()
    df_test_results['prediction'] = preds
    all_results_dfs.append(df_test_results)
    
    print(f"Fold {fold} ho√†n th√†nh.")

print(" Cross-Validation Ho√†n T·∫•t ")

#  3. T·ªïng h·ª£p v√† ƒê√°nh gi√° K·∫øt qu·∫£ 

all_results = pd.concat(all_results_dfs)
all_results['prediction'] = all_results['prediction'].apply(lambda x: max(0, x))
all_results_gt_zero = all_results[all_results['sales'] > 0]

print("\n üìä ƒê√°nh gi√° Hi·ªáu su·∫•t (M√¥ h√¨nh 2 - D√πng Tweedie) ")

performance_data = []

all_families_low = all_results['family'].unique()
print(f"ƒêang t√≠nh to√°n ch·ªâ s·ªë (c√≥ MAE) cho {len(all_families_low)} nh√≥m h√†ng c√≤n l·∫°i...")

for family in all_families_low:
    family_df = all_results[all_results['family'] == family]
    family_df_gt_zero = all_results_gt_zero[all_results_gt_zero['family'] == family]
    
    if len(family_df) == 0:
        continue

    # (TH√äM MAE)
    family_mae = mean_absolute_error(family_df['sales'], family_df['prediction'])
    family_rmse = np.sqrt(mean_squared_error(family_df['sales'], family_df['prediction']))
    family_r2 = r2_score(family_df['sales'], family_df['prediction'])
    
    if len(family_df_gt_zero) > 0:
        family_mape = mean_absolute_percentage_error(family_df_gt_zero['sales'], family_df_gt_zero['prediction']) * 100
        family_accuracy = 100 - family_mape
    else:
        family_mape = np.nan
        family_accuracy = np.nan
    
    performance_data.append({
        'family_name': family,
        'MAE': family_mae, # < TH√äM
        'RMSE': family_rmse,
        'R2': family_r2,
        'MAPE': family_mape,
        'Accuracy (%)': family_accuracy,
        'Count': len(family_df)
    })

# 3. T·∫°o file CSV b√°o c√°o
performance_df = pd.DataFrame(performance_data)
# S·∫Øp x·∫øp theo R2 (ch·ªâ s·ªë quan tr·ªçng nh·∫•t cho nh√≥m n√†y)
performance_df = performance_df.sort_values(by='R2', ascending=False) 

output_filename = 'xgb_model_2_low_volume_TWEEDIE_performance.csv'
performance_df.to_csv(output_filename, index=False, float_format='%.4f')

print("" * 10)
print(f"\n ƒê√£ l∆∞u M√¥ h√¨nh 2 v√†o file: {output_filename}")
total_time = time.time() - start_time
print(f"T·ªïng th·ªùi gian ch·∫°y: {total_time:.2f} gi√¢y.")

