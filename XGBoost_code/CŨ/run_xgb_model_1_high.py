import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, mean_absolute_error
import time

#  1. CÃ i Ä‘áº·t Cáº¥u hÃ¬nh (MÃ´ hÃ¬nh 1: NhÃ³m Biáº¿n Ä‘á»™ng cao) 

HIGH_VOLUME_FAMILIES = [
    'GROCERY I',
    'PRODUCE',
    'BEVERAGES',
    'DAIRY',
    'BREAD/BAKERY',
    'DELI',
    'EGGS'
]

N_FOLDS = 5

features = [
    'store_nbr', 'family', 'onpromotion', 'transactions', 
    'city', 'state', 'type', 'cluster', 'dcoilwtico', 
    'is_holiday', 'day_of_week', 'week_of_year', 'month', 'year', 
    'is_weekend', 'sales_lag_7', 'sales_lag_14', 'rolling_mean_30'
]
target = 'sales'

categorical_features = [
    'store_nbr', 'family', 'city', 'state', 'type', 
    'cluster', 'is_holiday', 'day_of_week', 'month', 'year', 'is_weekend'
]

all_original_sales = []
all_original_preds = []
all_original_family = []

print(f"Báº¯t Ä‘áº§u Káº¿ hoáº¡ch 'Chia Ä‘á»ƒ trá»‹' (MÃ´ hÃ¬nh 1 - Sá»­a lá»—i Log Transform)...")
print(f"Train cho {len(HIGH_VOLUME_FAMILIES)} nhÃ³m 'Biáº¿n Ä‘á»™ng cao' (trÃªn thang Log).")
start_time = time.time()

#  2. Cháº¡y VÃ²ng láº·p 5-Fold Cross-Validation 

for fold in range(1, N_FOLDS + 1):
    print(f" Äang cháº¡y Fold {fold}/{N_FOLDS} ")
    
    train_file = f'folds/train_fold_{fold}.csv'
    test_file = f'folds/test_fold_{fold}.csv'
    
    df_train = pd.read_csv(train_file)
    df_test = pd.read_csv(test_file)
    
    df_train = df_train[df_train['family'].isin(HIGH_VOLUME_FAMILIES)].copy()
    df_test = df_test[df_test['family'].isin(HIGH_VOLUME_FAMILIES)].copy()
    
    df_train[features] = df_train[features].fillna(0)
    df_test[features] = df_test[features].fillna(0)
    
    print(f"Fold {fold}: Äang xá»­ lÃ½ categorical features...")
    for col in categorical_features:
        all_categories = pd.concat([df_train[col], df_test[col]]).unique()
        df_train[col] = pd.Categorical(df_train[col], categories=all_categories)
        df_test[col] = pd.Categorical(df_test[col], categories=all_categories)

    X_train = df_train[features]
    X_test = df_test[features]
    
    y_train_log = np.log1p(df_train[target])
    y_test_log = np.log1p(df_test[target])
    y_test_orig = df_test[target]

    xgb_model = xgb.XGBRegressor(
        objective='reg:squarederror',
        eval_metric='rmse',
        n_estimators=2000,
        learning_rate=0.03,
        max_depth=8,
        subsample=0.8,
        colsample_bytree=0.8,
        n_jobs=-1,
        random_state=42,
        early_stopping_rounds=100,
        enable_categorical=True
    )
    
    print(f"Fold {fold}: Báº¯t Ä‘áº§u training XGBoost (trÃªn thang Log)...")
    xgb_model.fit(
        X_train, y_train_log,
        eval_set=[(X_test, y_test_log)],
        verbose=False
    )
    print(f"Fold {fold}: Training hoÃ n táº¥t. Báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n...")
    
    preds_log = xgb_model.predict(X_test)
    
    preds_orig = np.maximum(0, np.expm1(preds_log))
    
    all_original_sales.append(y_test_orig)
    all_original_preds.append(pd.Series(preds_orig, index=y_test_orig.index))
    all_original_family.append(df_test['family'])
    
    print(f"Fold {fold} hoÃ n thÃ nh.")

print(" Cross-Validation HoÃ n Táº¥t ")

#  3. Tá»•ng há»£p vÃ  ÄÃ¡nh giÃ¡ Káº¿t quáº£ 

df_results = pd.DataFrame({
    'family': pd.concat(all_original_family),
    'sales': pd.concat(all_original_sales),
    'prediction': pd.concat(all_original_preds)
})

print("\n ğŸ“Š ÄÃ¡nh giÃ¡ Hiá»‡u suáº¥t (MÃ´ hÃ¬nh 1 - ÄÃ£ Log Transform) ")

performance_data = []

for family in HIGH_VOLUME_FAMILIES:
    family_df = df_results[df_results['family'] == family]
    
    if len(family_df) == 0:
        continue

    family_mae = mean_absolute_error(family_df['sales'], family_df['prediction'])
    family_rmse = np.sqrt(mean_squared_error(family_df['sales'], family_df['prediction']))
    family_r2 = r2_score(family_df['sales'], family_df['prediction'])
    
    family_df_gt_zero = family_df[family_df['sales'] > 0]
    family_mape = mean_absolute_percentage_error(family_df_gt_zero['sales'], family_df_gt_zero['prediction']) * 100
    # Äá»‹nh nghÄ©a biáº¿n accuracy
    family_accuracy = 100 - family_mape
    
    performance_data.append({
        'family_name': family,
        'MAE': family_mae, 
        'RMSE': family_rmse,
        'R2': family_r2,
        'MAPE': family_mape,
        # (ÄÃ‚Y LÃ€ DÃ’NG ÄÃƒ Sá»¬A Lá»–I)
        # Sá»­a tá»« 'family_mape' thÃ nh 'family_accuracy'
        'Accuracy (%)': family_accuracy, 
        'Count': len(family_df)
    })
    
    print(f"\nNhÃ³m hÃ ng: {family}")
    print(f"  MAE (Sai sá»‘ tuyá»‡t Ä‘á»‘i): {family_mae:.4f}")
    print(f"  RMSE: {family_rmse:.4f}")
    print(f"  R2 (R-squared): {family_r2:.4f}")
    print(f"  MAPE: {family_mape:.4f}%")
    print(f"  Accuracy: {family_accuracy:.4f}%") # < Sáº½ in ra sá»‘ Ä‘Ãºng

# 3. Táº¡o file CSV bÃ¡o cÃ¡o
performance_df = pd.DataFrame(performance_data)
performance_df = performance_df.sort_values(by='Accuracy (%)', ascending=False) 

# Ghi Ä‘Ã¨ file cÅ©
output_filename = 'xgb_model_1_high_volume_LOG_performance.csv'
performance_df.to_csv(output_filename, index=False, float_format='%.4f')

print("" * 10)
print(f"\n ÄÃ£ lÆ°u MÃ´ hÃ¬nh 1 vÃ o file: {output_filename}")
total_time = time.time() - start_time
print(f"Tá»•ng thá»i gian cháº¡y: {total_time:.2f} giÃ¢y.")

